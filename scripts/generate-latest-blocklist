#!/bin/bash

#### Ensure are on borestad branch
git checkout borestad
####

#### Get latest abuseIPDB 10k IP list and combine with latest borestad abuseipdb-s100-1d list
echo "Getting latest abuseIPDB 10k IP list"
  abuseipdb_list="_generator_lists/abuseipdb-10k.list"
  source scripts/_abuseIPDB.key
  curl -Gs https://api.abuseipdb.com/api/v2/blacklist \
    -d confidenceMinimum=90 \
    -H "Key: $abuseIPDB_KEY" \
    -H "Accept: text/plain" \
    -o _generator_lists/abuseipdb-10k.list
echo "done"

echo "Getting latest borestad abuseipdb-s100-1d list"
  borestad_list="_generator_lists/abuseipdb-borestad.list"
  temp_file="_generator_lists/temp_abuseipdb-borestad.list"

  curl -s https://raw.githubusercontent.com/borestad/blocklist-abuseipdb/refs/heads/main/abuseipdb-s100-1d.ipv4 \
  -o $borestad_list
  
  grep -v '^#' $borestad_list | cut -d ' ' -f 1 > $temp_file
  mv "$temp_file" "$borestad_list"
echo "done"

echo "Combining abuseIPDB 10k IP list & borestad abuseipdb-s100-1d list as bad-ip-addresses.list"
  abuseipdb_list="_generator_lists/abuseipdb-10k.list"
  borestad_list="_generator_lists/abuseipdb-borestad.list"
  bad_ips="_generator_lists/bad-ip-addresses.list"
  temp_file="_generator_lists/temp_bad_ip-addresses.list"

  cat $borestad_list $abuseipdb_list | sort -u > $temp_file
  mv "$temp_file" "$bad_ips"

  rm $abuseipdb_list $borestad_list
echo "done"
####

#### Get latest lists from mitchellkrogza's repos
echo "Getting latest lists from mitchellkrogza's repos"
  upstreamlists="https://raw.githubusercontent.com/mitchellkrogza/nginx-ultimate-bad-bot-blocker/refs/heads/master/_generator_lists"
  upstreamlists_apache="https://raw.githubusercontent.com/mitchellkrogza/apache-ultimate-bad-bot-blocker/refs/heads/master/_generator_lists"
  files=(
    "allowed-user-agents.list"
    "bad-referrers.list"
    "bad-user-agents.list"
    "bing-ip-ranges.list"
    "bunnycdn-net.list"
    "cloudflare-ip-ranges.list"
    "fake-googlebots.list"
    "good-user-agents.list"
    "google-ip-ranges.list"
    "limited-user-agents.list"
    "nibbler-seo.list"
    "seo-analysis-tools.list"
    "wordpress-theme-detectors.list"
  )
  files_apache=(
    "bad-user-agents-fail2ban-additional.list"
    "wordpress-theme-detectors-apache.list"
  )
  for file in "${files[@]}"; do
    curl -s $upstreamlists/$file \
      -o _generator_lists/$file
  done
  for file in "${files_apache[@]}"; do
    curl -s $upstreamlists_apache/$file \
      -o _generator_lists/$file
  done
echo "done"
####

#### Get latest AI.Robots.txt list and add to bad-user-agents.list
ai_robots_txt="_generator_lists/ai-robots-txt.list"
bad_agents="_generator_lists/bad-user-agents.list"
temp_file="_generator_lists/temp_bad_user_agents.list"

echo "Getting latest AI.Robots.txt list"
  curl -s https://raw.githubusercontent.com/ai-robots-txt/ai.robots.txt/refs/heads/main/robots.txt \
    -o $ai_robots_txt
  sed -i '' -e 's/^User-agent: //g' -e '/^Disallow: /d' "$ai_robots_txt"
echo "done"

echo "Adding AI.Robots.txt list to bad-user-agents.list"
  cat "$bad_agents" <(grep -ivxFf "$bad_agents" "$ai_robots_txt") | sort -u > "$temp_file"
  mv "$temp_file" "$bad_agents"
echo "done"
####

#### Remove user agents for fedi compatability from bad-user-agents.list
allowed_agents="_generator_lists/allowed-user-agents-fedi.list"

echo "Removing user agents for fedi compatability from bad-user-agents.list"
  grep -ivxFf "$allowed_agents" "$bad_agents" > "$temp_file"
  mv "$temp_file" "$bad_agents"
echo "done"
####

#### Add additional user agents to bad-user-agents.list
extra_agents="_generator_lists/added-bad-user-agents.list"
echo "Adding additional user agents to bad-user-agents.list"
  cat "$bad_agents" <(grep -ivxFf "$bad_agents" "$extra_agents") | sort -u > "$temp_file"
  mv "$temp_file" "$bad_agents"
echo "done"
####

#### Change good user agents to bad
notgood_agents="_generator_lists/good-to-bad-user-agents.list"
good_agents="_generator_lists/good-user-agents.list"
bad_agents="_generator_lists/bad-user-agents.list"
temp_file="_generator_lists/temp_bad_user_agents.list"

echo "Removing good user agents that should be bad from good-user-agents.list"
  grep -ivFf "$notgood_agents" "$good_agents" > "$temp_file"
  mv "$temp_file" "$good_agents"
echo "done"

echo "Adding the removed good user agents to bad-user-agents.list"
  cat "$bad_agents" "$notgood_agents" | sort -u > "$temp_file"
  mv "$temp_file" "$bad_agents"
echo "done"
####

#### Get latest tor exits list from torproject.org & remove matches from bad-ip-addresses.list
tor_ips="_generator_lists/tor-exit-nodes.list"
bad_ips="_generator_lists/bad-ip-addresses.list"
temp_file="_generator_lists/temp_bad_ip-addresses.list"

echo "Getting latest tor exits list from torproject.org"
  curl -s https://check.torproject.org/torbulkexitlist \
    -o $tor_ips
echo "done"

echo "Removing tor exit node matches from bad-ip-addresses.list"
  grep -ivFf "$tor_ips" "$bad_ips" > "$temp_file"
  mv "$temp_file" "$bad_ips"
echo "done"
####

#### Get latest Oliphant Unified Tier 0 fedi blocklist
oliphant_tier0="_generator_lists/oliphant_unified_tier0.list"

echo "Getting latest Oliphant Unified Tier 0 fedi blocklist"
  curl -s https://raw.githubusercontent.com/sgrigson/oliphant/refs/heads/main/blocklists/_unified_tier0_blocklist.csv | \
  sed '1d' | cut -d',' -f1 > "$oliphant_tier0"
echo "done"
####

#### Get latest build number from mitchellkrogza's repos
echo "Get latest build number from mitchellkrogza's repos"
  curl -s https://raw.githubusercontent.com/mitchellkrogza/nginx-ultimate-bad-bot-blocker/refs/heads/master/dev-tools/buildnumber \
      -o _compiling/buildnumber.nginx
  #curl -s https://raw.githubusercontent.com/mitchellkrogza/apache-ultimate-bad-bot-blocker/refs/heads/master/dev-tools/buildnumber \
  #   -o _compiling/buildnumber.apache
echo "done"
####

#### Compile blocklist
./_compiling/compile-blocklist-nginx.sh
####
